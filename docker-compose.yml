version: '3.8'

services:
  postgres:
    image: postgres:14
    container_name: postgres
    user: "0:0"
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    volumes:
      - ${POSTGRES_DATA_PATH}:/var/lib/postgresql/data
    networks:
      - airflow_network
      

  airflow-init:
    image: apache/airflow:2.8.1
    depends_on:
      - postgres
    user: "50000:50000"  # Airflow 컨테이너의 사용자로 실행
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      #- AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:5432/airflow
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
    entrypoint: /bin/bash -c "airflow db init && airflow users create --username admin --firstname admin --lastname admin --role Admin --password admin --email admin@example.com"
    volumes:
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/dags:/opt/airflow/dags
      - ${DATA_PATH}:/opt/airflow/data
      - ./collector:/opt/airflow/data_collect
      - /root/.venv:/opt/venv  # 가상환경을 컨테이너에 마운트
    networks:
      - airflow_network

  airflow-webserver:
    image: apache/airflow:2.8.1
    container_name: airflow-webserver
    restart: always
    depends_on:
      - airflow-init
    ports:
      - "${AIRFLOW_WEB_PORT}:8080"
    user: "50000:50000"  # Airflow 컨테이너의 사용자로 실행
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      #- AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:5432/airflow
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
    command: webserver
    volumes:
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/dags:/opt/airflow/dags
      - ${DATA_PATH}:/opt/airflow/data
      - ./collector:/opt/airflow/data_collect
      - /root/.venv:/opt/venv  # 가상환경을 컨테이너에 마운트
    networks:
      - airflow_network

  airflow-scheduler:
    image: apache/airflow:2.8.1
    container_name: airflow-scheduler
    restart: always
    user: "50000:50000"  # Airflow 컨테이너의 사용자로 실행
    depends_on:
      - airflow-webserver
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      #- AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:5432/airflow
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
    command: scheduler
    volumes:
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/dags:/opt/airflow/dags
      - ${DATA_PATH}:/opt/airflow/data
      - ./collector:/opt/airflow/data_collect
      - /root/.venv:/opt/venv  # 가상환경을 컨테이너에 마운트
    networks:
      - airflow_network

  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    container_name: mlflow
    user: "0:0"
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - BACKEND_STORE_URI=postgresql+psycopg2://airflow:airflow@postgres:5432/mlflow_db
      - ARTIFACT_ROOT=/mlflow/artifacts
    ports:
      - "5000:5000"  # MLflow UI 접근
    volumes:
      - ./mlflow_artifacts:/mlflow/artifacts
    depends_on:
      - airflow-scheduler
    networks:
      - airflow_network
    command: mlflow ui --host 0.0.0.0 --port 5000
    
  collector:
    build:
      context: ./collector
      dockerfile: Dockerfile
    container_name: collector
    user: "0:0"
    #user: "50000:50000"  # Airflow 컨테이너의 사용자로 실행
    ports:
      - "${DATA_COLLECTOR_PORT}:8000"  # FastAPI 서버 포트 매핑
    depends_on:
      - airflow-scheduler
    volumes:
      - ${DATA_PATH}:/app/data
    networks:
      - airflow_network
  streamlit:
    build:
      context: ./data_GUI
      dockerfile: Dockerfile
    container_name: streamlit
    user: "0:0"
    #user: "50000:50000"  # Airflow 컨테이너의 사용자로 실행
    ports:
      - "${GUI_STREAMLIT_PORT}:8501"  # Streamlit 기본 포트
    depends_on:
      - airflow-scheduler
    volumes:
      - ${DATA_PATH}:/app/data
    networks:
      - airflow_network

volumes:
  postgres_data:

networks:
  airflow_network:
    driver: bridge